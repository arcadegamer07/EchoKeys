<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>FluteCast Studio ‚Äî Accessible</title>
  <meta name="viewport" content="width=400, initial-scale=1.0">
  <style>
    body { background: #18171c; font-family: 'Segoe UI', Arial, sans-serif; color: #fff; margin: 0; }
    .card { background: #22212a; border-radius: 16px; box-shadow: 0 2px 12px #0004; padding: 2em; margin: 1em; display: inline-block; vertical-align: top; width: 28%; text-align: center;}
    .icon { background: #8243ea; border-radius: 50%; padding: 1em; display: inline-block; margin-bottom: 1em;}
    .main-title { font-size: 2em; margin-top: 2em; margin-bottom: 0.5em;}
    .subtitle, .instructions { color: #aaa; font-size: 1.05em; margin: 1em 0;}
    .status { color: #a68aff; margin-top: 1em; font-weight: bold; font-size: 1.15em;}
    .player-card { background: #22212a; border-radius: 16px; box-shadow: 0 2px 12px #0004; padding: 2em; margin: 1em; display: flex; justify-content: space-between;}
    .player-left, .player-right { width: 48%; }
    .purple { color: #a68aff; }
    button, .download-btn {
      background: #8243ea; color: #fff; border: none; border-radius: 6px; padding: 0.7em 2em; margin: 1em 0.5em; font-size: 1em; cursor: pointer; transition: background 0.2s;
    }
    button:disabled, .download-btn:disabled { background: #393353; cursor: not-allowed;}
    button:focus { outline: 2px solid #a68aff; }
    #notes-guide { margin-top: 2em; background: #18171c; border-radius: 12px; padding: 1em; color: #fff; font-size: 1em; text-align: center;}
    table { margin: auto; color: #fff; border-collapse: collapse; margin-bottom: 0.5em; }
    td { border: 1px solid #393353; padding: 0.6em 1.2em; font-size: 1.1em; }
    #canvas { position: absolute; left: 0; top: 0; }
    #loadingSpinner { display: block; margin: 2em auto; width: 40px; height: 40px; border: 5px solid #a68aff; border-radius: 50%; border-top: 5px solid #22212a; animation: spin 1s linear infinite;}
    @keyframes spin { 100% { transform: rotate(360deg);} }
    #cameraStatus { margin-top: 0.7em; font-size: 1.1em; color: #a68aff; }
    .sr-only { position:absolute; left:-9999px; width:1px; height:1px; overflow:hidden;}
  </style>
</head>
<body>
  <div>
    <div class="card" aria-label="Hand Tracking feature">
      <span class="icon" aria-hidden="true">üñêÔ∏è</span>
      <h2>Hand Tracking</h2>
      <span>Advanced AI-powered hand landmark detection with purple visual feedback</span>
    </div>
    <div class="card" aria-label="Audio Synthesis feature">
      <span class="icon" aria-hidden="true">üéµ</span>
      <h2>Audio Synthesis</h2>
      <span>Real-time flute sound generation with natural envelope curves</span>
    </div>
    <div class="card" aria-label="Record and Export feature">
      <span class="icon" aria-hidden="true">‚ö°</span>
      <h2>Record & Export</h2>
      <span>Capture your musical performances and download as audio files</span>
    </div>
  </div>
  <div class="main-title">Your Virtual Flute Studio</div>
  <div class="subtitle" id="app-instructions">
    Move your hands up and down to play different notes.<br>
    <div class="instructions">Allow camera access when prompted. Use <b>Tab</b> to navigate. Press <b>Space</b> or <b>Enter</b> to play/record.</div>
  </div>
  <div class="player-card">
    <div class="player-left" style="position:relative;">
      <span class="purple status" id="handTrackingStatus">‚óè Hand Tracking Active</span><br>
      <video id="video" width="300" height="220" autoplay muted playsinline aria-label="Your hand camera view" tabindex="0" style="display:block; margin: auto; background: #111;"></video>
      <canvas id="canvas" width="300" height="220" aria-hidden="true"></canvas>
      <div id="loadingSpinner" aria-live="polite"></div>
      <div id="cameraStatus" aria-live="polite">Initializing camera...</div>
      <div style="margin-top: 2em; color: #a68aff; font-weight: bold;" id="notePlayed" aria-live="polite" tabindex="0"></div>
    </div>
    <div class="player-right">
      <h2 class="purple">üé∂ FluteCast Player</h2>
      <div>Position your hands to play flute notes</div>
      <button id="startRec" aria-label="Start Recording" tabindex="0">Start Recording</button>
      <button id="stopRec" aria-label="Stop Recording" tabindex="0" disabled>Stop</button>
      <a id="downloadLink" class="download-btn" style="display:none" aria-label="Download recording" tabindex="0">Download</a>
      <div id="notes-guide">
        <b>Hand Position Guide</b><br><br>
        <table aria-label="Hand Positions to Flute Notes">
          <tr><td>C4</td><td>D4</td><td>E4</td><td>F4</td></tr>
          <tr><td>G4</td><td>A4</td><td>B4</td><td>C5</td></tr>
        </table>
        Higher hand positions play higher notes
      </div>
    </div>
  </div>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/tone@next/build/Tone.js"></script>
  <script>
    const videoEl = document.getElementById('video');
    const canvasEl = document.getElementById('canvas');
    const ctx = canvasEl.getContext('2d');
    const cameraStatus = document.getElementById('cameraStatus');
    const loadingSpinner = document.getElementById('loadingSpinner');

    // Accessible feedback
    function setStatus(msg, color="#a68aff") {
      cameraStatus.textContent = msg;
      cameraStatus.style.color = color;
    }

    // Synth: continuous sound
    const fluteSynth = new Tone.Synth({
      oscillator: {type: 'sine'},
      envelope: {attack: 0.02, decay: 0.25, sustain: 0.85, release: 0.15}
    }).toDestination();
    let playingNote = null;
    let lastGesture = null;

    // Hand gesture mapping
    const notesMap = {
      'fist': 'C4', 'indexUp': 'D4', 'middleUp': 'E4', 'ringUp': 'F4', 'allOpen': 'G4'
    };

    // Camera setup/status feedback
    async function setupCamera() {
      try {
        videoEl.srcObject = await navigator.mediaDevices.getUserMedia({ video: true });
        videoEl.onloadeddata = function() {
          loadingSpinner.style.display = "none";
          setStatus("Camera Active");
        };
      } catch (e) {
        loadingSpinner.style.display = "none";
        setStatus("Camera Error", "#f55");
      }
    }
    setupCamera();

    // Mediapipe hands initialization
    const hands = new Hands({locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`});
    hands.setOptions({ maxNumHands: 1, modelComplexity: 1, minDetectionConfidence: 0.7, minTrackingConfidence: 0.7 });
    hands.onResults(onResults);

    const camera = new Camera(videoEl, {
      onFrame: async () => await hands.send({image: videoEl}),
      width: 300, height: 220
    });
    camera.start();

    function getHandGesture(landmarks) {
      if (!landmarks) return null;
      const indexUp = landmarks[8].y < landmarks[6].y;
      const middleUp = landmarks[12].y < landmarks[10].y;
      const ringUp = landmarks[16].y < landmarks[14].y;
      if (!indexUp && !middleUp && !ringUp) return 'fist';
      if (indexUp && !middleUp && !ringUp) return 'indexUp';
      if (indexUp && middleUp && !ringUp) return 'middleUp';
      if (indexUp && middleUp && ringUp) return 'allOpen';
      return null;
    }

    // Draw landmarks/connections in purple, play continuous flute notes
    function onResults({multiHandLandmarks}) {
      ctx.clearRect(0,0,canvasEl.width,canvasEl.height);
      if (multiHandLandmarks && multiHandLandmarks.length > 0) {
        const landmarks = multiHandLandmarks[0];
        // Connections in purple
        ctx.strokeStyle = "#a68aff"; ctx.lineWidth = 2;
        const connections = [
          [0,1],[1,2],[2,3],[3,4],[0,5],[5,6],[6,7],[7,8],
          [0,9],[9,10],[10,11],[11,12],[0,13],[13,14],[14,15],[15,16],
          [0,17],[17,18],[18,19],[19,20]
        ];
        connections.forEach(([a,b]) => {
          ctx.beginPath();
          ctx.moveTo(landmarks[a].x * canvasEl.width, landmarks[a].y * canvasEl.height);
          ctx.lineTo(landmarks[b].x * canvasEl.width, landmarks[b].y * canvasEl.height);
          ctx.stroke();
        });
        // Points in purple
        for (let pt of landmarks) {
          ctx.beginPath();
          ctx.arc(pt.x * canvasEl.width, pt.y * canvasEl.height, 6, 0, 2 * Math.PI);
          ctx.fillStyle = "#a68aff"; ctx.fill();
        }
        // Gesture ‚Üí note
        const gesture = getHandGesture(landmarks);
        if (gesture && notesMap[gesture]) {
          if (!playingNote || lastGesture !== gesture) {
            fluteSynth.triggerAttack(notesMap[gesture]);
            playingNote = notesMap[gesture];
            lastGesture = gesture;
            document.getElementById('notePlayed').textContent = `Note: ${notesMap[gesture]}`;
          }
        } else {
          if (playingNote) {
            fluteSynth.triggerRelease();
            playingNote = null;
            document.getElementById('notePlayed').textContent = '';
          }
        }
      } else {
        // No hand = silence
        if (playingNote) {
          fluteSynth.triggerRelease();
          playingNote = null;
          document.getElementById('notePlayed').textContent = '';
        }
      }
    }

    // Accessible recording: Tone.Recorder; keyboard-friendly
    let recorder = new Tone.Recorder();
    fluteSynth.connect(recorder);

    document.getElementById('startRec').onclick = async () => {
      await Tone.start(); // Ensure synth is unlocked
      recorder.start();
      document.getElementById('startRec').disabled = true;
      document.getElementById('stopRec').disabled = false;
      setStatus("Recording in progress...");
    };

    document.getElementById('stopRec').onclick = async () => {
      const recordingData = await recorder.stop();
      const blob = new Blob([recordingData], { type: "audio/wav" });
      const url = URL.createObjectURL(blob);
      const link = document.getElementById('downloadLink');
      link.href = url;
      link.download = "EchoKeys.wav";
      link.style.display = "inline";
      document.getElementById('startRec').disabled = false;
      document.getElementById('stopRec').disabled = true;
      setStatus("Camera Active"); // reset prompt
    };
  </script>
</body>
</html>
