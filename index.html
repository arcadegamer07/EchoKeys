<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>FluteCast Studio</title>
  <style>
    body { background: #18171c; font-family: 'Segoe UI', 'Arial', sans-serif; color: #fff; margin: 0; }
    .card { background: #22212a; border-radius: 16px; box-shadow: 0 2px 12px #0004; padding: 2em; margin: 1em; display: inline-block; vertical-align: top; width: 28%; text-align: center;}
    .icon { background: #8243ea; border-radius: 50%; padding: 1em; display: inline-block; margin-bottom: 1em;}
    .main-title { font-size: 2em; margin-top: 2em; margin-bottom: 0.5em;}
    .subtitle { color: #aaa; font-size: 1.1em; margin-bottom: 2em;}
    .status { color: #a68aff; margin-top: 1em; font-weight: bold; font-size: 1.15em;}
    .player-card { background: #22212a; border-radius: 16px; box-shadow: 0 2px 12px #0004; padding: 2em; margin: 1em; display: flex; justify-content: space-between;}
    .player-left, .player-right { width: 48%; }
    .purple { color: #a68aff; }
    button, .download-btn {
      background: #8243ea; color: #fff; border: none; border-radius: 6px; padding: 0.7em 2em; margin: 1em 0.5em; font-size: 1em; cursor: pointer; transition: background 0.2s;
    }
    button:disabled, .download-btn:disabled { background: #393353; cursor: not-allowed;}
    #notes-guide { margin-top: 2em; background: #18171c; border-radius: 12px; padding: 1em; color: #fff; font-size: 1em; text-align: center; letter-spacing: 1px;}
    table { margin: auto; color: #fff; border-collapse: collapse; margin-bottom: 0.5em; }
    td { border: 1px solid #393353; padding: 0.6em 1.2em; font-size: 1.1em; }
    #canvas { position: absolute; left: 0; top: 0; }
    #loadingSpinner { display: block; margin: 2em auto; width: 40px; height: 40px; border: 5px solid #a68aff; border-radius: 50%; border-top: 5px solid #22212a; animation: spin 1s linear infinite;}
    @keyframes spin { 100% { transform: rotate(360deg);} }
    #cameraStatus { margin-top: 0.7em; font-size: 1.1em; color: #a68aff; }
  </style>
</head>
<body>
  <div>
    <div class="card">
      <span class="icon">üñêÔ∏è</span>
      <h2>Hand Tracking</h2>
      <span>Advanced AI-powered hand landmark detection with purple visual feedback</span>
    </div>
    <div class="card">
      <span class="icon">üéµ</span>
      <h2>Audio Synthesis</h2>
      <span>Real-time flute sound generation with natural envelope curves</span>
    </div>
    <div class="card">
      <span class="icon">‚ö°</span>
      <h2>Record & Export</h2>
      <span>Capture your musical performances and download as audio files</span>
    </div>
  </div>
  <div class="main-title">Your Virtual Flute Studio</div>
  <div class="subtitle">Move your hands up and down to play different notes</div>
  <div class="player-card">
    <div class="player-left" style="position:relative;">
      <span class="purple status">‚óè Hand Tracking Active</span><br>
      <video id="video" width="300" height="220" autoplay muted playsinline style="display:block; margin: auto; background: #111;"></video>
      <canvas id="canvas" width="300" height="220"></canvas>
      <div id="loadingSpinner"></div>
      <div id="cameraStatus">Initializing camera...</div>
      <div style="margin-top: 2em; color: #a68aff; font-weight: bold;" id="notePlayed"></div>
    </div>
    <div class="player-right">
      <h2 class="purple">üé∂ FluteCast Player</h2>
      <div>Position your hands to play flute notes</div>
      <button id="startRec">Start Recording</button>
      <button id="stopRec" disabled>Stop</button>
      <a id="downloadLink" class="download-btn" style="display:none">Download</a>
      <div id="notes-guide">
        <b>Hand Position Guide</b><br><br>
        <table>
          <tr><td>C4</td><td>D4</td><td>E4</td><td>F4</td></tr>
          <tr><td>G4</td><td>A4</td><td>B4</td><td>C5</td></tr>
        </table>
        Higher hand positions play higher notes
      </div>
    </div>
  </div>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/tone@next/build/Tone.js"></script>
  <script>
    const videoEl = document.getElementById('video');
    const canvasEl = document.getElementById('canvas');
    const ctx = canvasEl.getContext('2d');
    const cameraStatus = document.getElementById('cameraStatus');
    const loadingSpinner = document.getElementById('loadingSpinner');

    // Create continuous flute synth
    const fluteSynth = new Tone.Synth({
      oscillator: {type: 'sine'},
      envelope: {attack: 0.02, decay: 0.25, sustain: 0.8, release: 0.5}
    }).toDestination();
    let playingNote = null;
    let lastGesture = null;

    // Hand gesture mapping (expand as desired)
    const notesMap = {
      'fist': 'C4', 'indexUp': 'D4', 'middleUp': 'E4', 'ringUp': 'F4', 'allOpen': 'G4'
    };

    // Camera setup/status feedback
    async function setupCamera() {
      try {
        videoEl.srcObject = await navigator.mediaDevices.getUserMedia({ video: true });
        videoEl.onloadeddata = function() {
          loadingSpinner.style.display = "none";
          cameraStatus.textContent = "Camera Active";
          cameraStatus.style.color = "#a68aff";
        };
      } catch (e) {
        loadingSpinner.style.display = "none";
        cameraStatus.textContent = "Camera Error";
        cameraStatus.style.color = "#f55";
      }
    }
    setupCamera();

    // Mediapipe hands initialization
    const hands = new Hands({locateFile: file => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`});
    hands.setOptions({ maxNumHands: 1, modelComplexity: 1, minDetectionConfidence: 0.7, minTrackingConfidence: 0.7 });
    hands.onResults(onResults);

    const camera = new Camera(videoEl, {
      onFrame: async () => await hands.send({image: videoEl}),
      width: 300, height: 220
    });
    camera.start();

    // Basic gesture detection logic
    function getHandGesture(landmarks) {
      if (!landmarks) return null;
      const indexUp = landmarks[8].y < landmarks[6].y;
      const middleUp = landmarks[12].y < landmarks[10].y;
      const ringUp = landmarks[16].y < landmarks[14].y;
      if (!indexUp && !middleUp && !ringUp) return 'fist';
      if (indexUp && !middleUp && !ringUp) return 'indexUp';
      if (indexUp && middleUp && !ringUp) return 'middleUp';
      if (indexUp && middleUp && ringUp ) return 'allOpen';
      return null;
    }

    // Drawing landmarks/connections in purple, playing/flute logic
    function onResults({multiHandLandmarks}) {
      ctx.clearRect(0,0,canvasEl.width,canvasEl.height);
      if (multiHandLandmarks && multiHandLandmarks.length > 0) {
        const landmarks = multiHandLandmarks[0];
        // Draw connections in purple
        ctx.strokeStyle = "#a68aff";
        ctx.lineWidth = 2;
        const connections = [
          [0,1],[1,2],[2,3],[3,4],[0,5],[5,6],[6,7],[7,8],
          [0,9],[9,10],[10,11],[11,12],[0,13],[13,14],[14,15],[15,16],
          [0,17],[17,18],[18,19],[19,20]
        ];
        connections.forEach(([a,b]) => {
          ctx.beginPath();
          ctx.moveTo(landmarks[a].x * canvasEl.width, landmarks[a].y * canvasEl.height);
          ctx.lineTo(landmarks[b].x * canvasEl.width, landmarks[b].y * canvasEl.height);
          ctx.stroke();
        });
        // Draw points in purple
        for (let pt of landmarks) {
          ctx.beginPath();
          ctx.arc(pt.x * canvasEl.width, pt.y * canvasEl.height, 6, 0, 2 * Math.PI);
          ctx.fillStyle = "#a68aff";
          ctx.fill();
        }
        // Gesture ‚Üí note
        const gesture = getHandGesture(landmarks);
        if (gesture && notesMap[gesture]) {
          if (!playingNote || lastGesture !== gesture) {
            fluteSynth.triggerAttack(notesMap[gesture]);
            playingNote = notesMap[gesture];
            lastGesture = gesture;
            document.getElementById('notePlayed').textContent = `Note: ${notesMap[gesture]}`;
          }
        } else {
          if (playingNote) {
            fluteSynth.triggerRelease();
            playingNote = null;
            document.getElementById('notePlayed').textContent = '';
          }
        }
      } else {
        // No hand = silence
        if (playingNote) {
          fluteSynth.triggerRelease();
          playingNote = null;
          document.getElementById('notePlayed').textContent = '';
        }
      }
    }

    // Recording using Tone.Recorder (best with Tone.js, robust for browser audio synth)
    let recorder = new Tone.Recorder();
    fluteSynth.connect(recorder);

    document.getElementById('startRec').onclick = async () => {
      await Tone.start(); // Ensure synth is running
      recorder.start();
      document.getElementById('startRec').disabled = true;
      document.getElementById('stopRec').disabled = false;
    };

    document.getElementById('stopRec').onclick = async () => {
      const recordingData = await recorder.stop();
      const blob = new Blob([recordingData], { type: "audio/wav" });
      const url = URL.createObjectURL(blob);
      const link = document.getElementById('downloadLink');
      link.href = url;
      link.download = "EchoKeys.wav";
      link.style.display = "inline";
      document.getElementById('startRec').disabled = false;
      document.getElementById('stopRec').disabled = true;
    };
  </script>
</body>

</html>
